# TenviRAG


A lightweight **researchâ€‘assistant platform** that lets you _chat_ with T&E's publication built with the help of LLMs.
It couples a **FAISS** vector store with a **Streamlit** UI that offers both RAG-powered search and an AIâ€‘powered chat interface.

<p align="center">
  <img src="figures/user_experience.gif" alt="Demo animation" width="700">
</p>

---

## âœ¨ Key Features

| Area | Highlights |
|------|------------|
| **Semantic Search** | â€¢ Sentenceâ€‘Transformer embeddings ('multilingual-e5-small') with multi-language support <br>â€¢ Optional exponential **dateâ€‘decay** weighting so fresh material floats to the top |
| **Storage** | â€¢ FAISS HNSW index for millisecond retrieval<br>â€¢ All vectors + metadata **persisted** on disk |
| **Streamlit Frontâ€‘End** | â€¢ Responsive twoâ€‘tab layout â€“ **Search** & **Chat**<br>â€¢ Clickable results with similarity colouring<br>â€¢ Floating chat bar, expert settings sliders |
| **Retrievalâ€‘Augmented Chat (RAG)** | â€¢ Router decides when to query the corpus<br>â€¢ Sources block with inline `[1]` citations |
| **Extensibility** | Simple, modular Python; swap embedding models, adjust ranking, plugâ€‘in new data loaders |

---

## ğŸ›  Installation

### 1. Prerequisites
* PythonÂ â‰¥Â 3.8
* `pip` package manager
* (optional) `virtualenv` or `conda`

### 2. Clone & set up
```bash
git clone https://github.com/KunkelAlexander/t-e_search_tool.git
cd t-e_search_tool
python -m venv venv                 # optional but recommended
source venv/bin/activate            # Windows: venv\Scripts\activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Configure
Edit **`config.py`** (paths, model names, index size, etc.).
At runtime, supply your **OpenAI key** via:

* the Streamlit sidebar input

---

## ğŸš€ Usage

### 1. Build / update the index
```bash
build_index.ipynb   # scrapes PDFs â†’ embeddings â†’ FAISS
```
Adjust model, chunk size and filters in `config.py`.

### 2. Launch the UI
```bash
streamlit run frontend/app.py
```

### 3. Search
*Switch to the **Search** tab, type a query.*
Results show publication type, date and a colourâ€‘coded match score.

### 4. Chat
Ask conversational questions in the **Chat** tab.
The assistant will cite snippets (`[1]`) and list full sources below its answer.

---

## âš™ Expert Settings (in the sidebar)

| Control | Effect |
|---------|--------|
| **# Search Results** | topâ€‘*k* candidates returned from FAISS |
| **Date DecayÂ Î±** | how strongly older docs are downâ€‘weighted |
| **Max Snippet Length** | truncate long excerpts for brevity |

---

## ğŸ§‘â€ğŸ’» Project Structure

```
app.py              main entry point
search.py           implement rag retrieval and chat using langchain
build_index.ipynb   create faiss vector database and read pdfs
embeddings/         cached artefacts (index, parquet mapping,â€¦)
figures/            screenshots / GIFs
```

## ğŸŒ± Roadmap

* Faceted filters (author, year, tag) in the UI
* Scheduled crawler to autoâ€‘ingest new publications

---

## ğŸ“ License
[MIT](LICENSE)

---

## ğŸ”– Disclaimer
This is a personal sideâ€‘project by **AlexanderÂ Kunkel**.
It is **not** an official product of **TransportÂ &Â Environment** and reflects only the authorâ€™s views.
Use at your own discretion.
